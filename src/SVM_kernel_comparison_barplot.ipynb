{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Kernel Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2b5ee89229654fc7a5b05e806e4fd1d6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "4787f45c-c6ac-42a7-9147-88c811b6ab31",
    "execution_millis": 1186,
    "execution_start": 1724415811200,
    "source_hash": "11e45cf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_barplot(data_type: str, input_folder: str, output_folder: str, metric: str) -> None:\n",
    "    \n",
    "    '''\n",
    "    Barplot showing the average perfomances across the experiments of different kernels of ls-gkm.\n",
    "    \n",
    "    \n",
    "    data_type: one of the following [\"dnase-shuffle\", \"shuffle-dnase\", \"dnase\", \"shuffle\"]\n",
    "    input_folder: folder containing all the data regarding dnase, shuffle, dnase-shuffle and shuffle-dnase\n",
    "    output_folder: where the barplot will be created, structured based on the data_type \n",
    "    metric: one of the following [\"auroc\",\"auprc\", \"f1score\"]\n",
    "    \n",
    "    It creates the barplot regarding the selected data_type, metric and dataset_size, retrieving the data from the \n",
    "    \"{input_folder}/{data_type}/dataset-size-comparison\" folder and saving it in the \n",
    "    \"{output_folder}/{data_type}/dataset_size_comparison_barplot\" barplot.\n",
    "\n",
    "    '''\n",
    "        \n",
    "        \n",
    "    possible_data_types = [\"dnase-shuffle\", \"shuffle-dnase\", \"dnase\", \"shuffle\"]\n",
    "    if data_type not in possible_data_types:\n",
    "        raise ValueError(f\"data_type must be one of the following: {possible_data_types}\")\n",
    "    \n",
    "    possible_metrics = [\"auroc\",\"auprc\", \"f1score\"]\n",
    "    if metric not in possible_metrics:\n",
    "        raise ValueError(f\"metric must be one of the following: {possible_metrics}\")\n",
    "        \n",
    "    \n",
    "    # Set the input and output folder\n",
    "    color  = {\"est_lmer\": \"#191970ff\",\n",
    "              \"gapped_kmer\": \"#800080ff\",\n",
    "              \"gkm\": \"#666666ff\",\n",
    "              \"wgkm\": \"#008000ff\",\n",
    "              \"wgkmrbf\": \"#ffc0cbff\",\n",
    "              \"gkmrbf\": \"#ffa500ff\"\n",
    "             }\n",
    "    kernels = ['wgkm', 'wgkmrbf', 'est_lmer', 'gkm', 'gkmrbf', 'gapped_kmer']\n",
    "\n",
    "    data_folder = f\"{input_folder}/{data_type}/svm-kernel-comparison\"\n",
    "    output_folder = f\"{output_folder}/{data_type}/svm_kernel_comparison_barplot\"\n",
    "\n",
    "    # Create the output folder(s)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    kernel_data = {}\n",
    "    for kernel in kernels:\n",
    "        kernel_name = re.sub(\"_\", \"\", kernel) if \"_\" in kernel else kernel\n",
    "        kernel_data[kernel_name] = pd.read_csv(f\"{data_folder}/summary_table_full_{kernel}.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    \n",
    "    # Retrieve the data refering to AUROC only\n",
    "    metric_col_name = \"F1\" if metric == \"f1score\" else metric.upper()\n",
    "    metric_data = {}\n",
    "    for kernel, df in kernel_data.items():\n",
    "        metric_cols = [col for col in df.columns if col.startswith(metric_col_name) or col.startswith(\"EXP\")]\n",
    "        metric_data[kernel] = df[metric_cols]\n",
    "\n",
    "    # Compute for each tool and width the mean and standard deviation\n",
    "    metric_mean_dicts = {}\n",
    "    metric_std_dicts = {}\n",
    "    for kernel, df in metric_data.items():\n",
    "        k = df.columns[1].split(\"_\",3)[3]\n",
    "        means = [df[col].mean().round(3) for col in df.columns[1:]]\n",
    "        stds = [df[col].std().round(3) for col in df.columns[1:]]\n",
    "        tool_means = dict(zip([col.split(\"_\",3)[3] for col in df.columns[1:]], means))\n",
    "        tool_stds = dict(zip([col.split(\"_\",3)[3] for col in df.columns[1:]], stds))\n",
    "\n",
    "        metric_mean_dicts[k] = tool_means[k]\n",
    "        metric_std_dicts[k] = tool_stds[k]\n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.subplots(figsize =(20,15))\n",
    "    ax = plt.gca()\n",
    "    color_mapping = [color[key] for key in metric_mean_dicts.keys()]\n",
    "\n",
    "    plt.bar(metric_mean_dicts.keys(),metric_mean_dicts.values(),color = color_mapping,edgecolor =\"grey\",zorder=3)\n",
    "    for k,v in metric_std_dicts.items():\n",
    "        plt.text(k,metric_mean_dicts[k]+0.075,str(\"std\"), horizontalalignment = \"center\", fontsize = 15)\n",
    "        plt.text(k,metric_mean_dicts[k]+0.055,str(f'{v:.3f}'), horizontalalignment = \"center\", fontsize = 15)\n",
    "        plt.text(k,metric_mean_dicts[k]+0.03,str(\"mean\"), horizontalalignment = \"center\", fontsize = 15)\n",
    "        plt.text(k,metric_mean_dicts[k]+0.01,str(f'{metric_mean_dicts[k]:.3f}'), horizontalalignment = \"center\", fontsize = 15)\n",
    "\n",
    "    plt.yticks(fontsize = 15)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.grid(axis = \"y\",zorder=0,alpha=0.3)\n",
    "    ylabel = \"F1-Score\" if metric == \"f1score\" else metric.upper()\n",
    "    plt.ylabel(ylabel,fontsize=30)\n",
    "    plt.xlabel(\"Kernels\",fontsize=30)\n",
    "    plt.title(f\"{data_type} {ylabel} Mean of Kernels\",fontsize=30)\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    plt.savefig(f\"{output_folder}/{data_type}_{ylabel}_Mean_Kernels.png\", dpi = 300)\n",
    "    plt.savefig(f\"{output_folder}/{data_type}_{ylabel}_Mean_Kernels.svg\", dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f25d08c7c1df49478c49e8c489e964d7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "4787f45c-c6ac-42a7-9147-88c811b6ab31",
    "execution_millis": 139,
    "execution_start": 1724415812636,
    "source_hash": "27d5de51"
   },
   "outputs": [],
   "source": [
    "kernel_barplot(data_type= \"\", input_folder= \"\", output_folder= \"\", metric= \"\")"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "c2f7cf09363945cdb23b7b33ffb0f552",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
